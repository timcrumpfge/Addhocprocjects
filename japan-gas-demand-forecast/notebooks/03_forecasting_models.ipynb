{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2520f4b",
   "metadata": {},
   "source": [
    "# Japan Gas Demand Forecasting Models\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook implements and compares multiple forecasting approaches for Japanese natural gas demand:\n",
    "\n",
    "### Model Categories\n",
    "\n",
    "1. **Traditional Time Series Models**\n",
    "   - ARIMA/SARIMA with automatic parameter selection\n",
    "   - Exponential Smoothing (Holt-Winters)\n",
    "   - State Space models\n",
    "\n",
    "2. **Machine Learning Models**\n",
    "   - Random Forest with lag features\n",
    "   - XGBoost for gradient boosting\n",
    "   - Support Vector Regression\n",
    "\n",
    "3. **Advanced Methods**\n",
    "   - Prophet for handling holidays and multiple seasonalities\n",
    "   - Ensemble methods combining multiple models\n",
    "\n",
    "### Evaluation Framework\n",
    "\n",
    "- Time series cross-validation with walk-forward approach\n",
    "- Multiple accuracy metrics: MAE, RMSE, MAPE, Directional Accuracy\n",
    "- Statistical significance testing\n",
    "- Residual analysis and diagnostic checking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e597910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for forecasting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "import joblib\n",
    "\n",
    "# Time series modeling\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from prophet import Prophet\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# Plotting\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Import our custom modules\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from forecasting_utils import (\n",
    "    calculate_forecast_metrics, time_series_cv_split, \n",
    "    ForecastEvaluator, plot_forecast_results\n",
    ")\n",
    "\n",
    "# Set styling and suppress warnings\n",
    "plt.style.use('seaborn-v0_8')\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"üöÄ Japan Gas Demand Forecasting Models\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üìÖ Model development started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"‚úÖ Forecasting libraries imported successfully\")\n",
    "print(\"‚úÖ Custom utilities loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f00d584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processed dataset\n",
    "print(\"üìä LOADING DATASET FOR MODELING\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "try:\n",
    "    # Try to load from the processed data file\n",
    "    gas_data = pd.read_csv('../data/processed/japan_gas_demand_processed.csv', index_col=0, parse_dates=True)\n",
    "    print(\"‚úÖ Loaded processed dataset from file\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö†Ô∏è Processed data file not found, generating fresh dataset...\")\n",
    "    # Generate fresh data if file doesn't exist\n",
    "    from data_processing import JapanGasDataCollector\n",
    "    collector = JapanGasDataCollector()\n",
    "    gas_data = collector.generate_synthetic_data('2018-01-01', '2024-08-31')\n",
    "    gas_data = collector.add_calendar_features(gas_data)\n",
    "    gas_data = collector.create_lagged_features(gas_data, 'total_gas_demand_mcm', max_lag=12)\n",
    "    gas_data = collector.clean_and_validate_data(gas_data)\n",
    "    print(\"‚úÖ Generated fresh synthetic dataset\")\n",
    "\n",
    "# Prepare data for modeling\n",
    "target_col = 'total_gas_demand_mcm'\n",
    "y = gas_data[target_col].dropna()\n",
    "\n",
    "print(f\"üìà Dataset Overview:\")\n",
    "print(f\"   ‚Ä¢ Period: {gas_data.index.min().strftime('%Y-%m')} to {gas_data.index.max().strftime('%Y-%m')}\")\n",
    "print(f\"   ‚Ä¢ Total observations: {len(gas_data):,}\")\n",
    "print(f\"   ‚Ä¢ Target variable: {target_col}\")\n",
    "print(f\"   ‚Ä¢ Valid target observations: {len(y):,}\")\n",
    "\n",
    "# Display basic statistics\n",
    "print(f\"\\nüìä Target Variable Statistics:\")\n",
    "print(f\"   ‚Ä¢ Mean: {y.mean():.2f} million m¬≥/month\")\n",
    "print(f\"   ‚Ä¢ Std Dev: {y.std():.2f} million m¬≥/month\")\n",
    "print(f\"   ‚Ä¢ Min: {y.min():.2f} million m¬≥/month\")\n",
    "print(f\"   ‚Ä¢ Max: {y.max():.2f} million m¬≥/month\")\n",
    "print(f\"   ‚Ä¢ Coefficient of Variation: {(y.std()/y.mean()*100):.1f}%\")\n",
    "\n",
    "# Check stationarity\n",
    "print(f\"\\nüîç Stationarity Check:\")\n",
    "stationarity_result = adfuller(y)\n",
    "print(f\"   ‚Ä¢ ADF Statistic: {stationarity_result[0]:.4f}\")\n",
    "print(f\"   ‚Ä¢ P-value: {stationarity_result[1]:.4f}\")\n",
    "print(f\"   ‚Ä¢ Critical Values:\")\n",
    "for key, value in stationarity_result[4].items():\n",
    "    print(f\"     {key}: {value:.4f}\")\n",
    "print(f\"   ‚Ä¢ Stationary: {'Yes' if stationarity_result[1] < 0.05 else 'No'}\")\n",
    "\n",
    "# Prepare feature matrix for ML models\n",
    "feature_cols = [\n",
    "    'avg_temperature_celsius', 'heating_degree_days', 'cooling_degree_days',\n",
    "    'month_sin', 'month_cos', 'day_of_year_sin', 'day_of_year_cos',\n",
    "    'is_winter', 'is_spring', 'is_summer', 'is_autumn',\n",
    "    'gdp_growth_rate_pct', 'industrial_production_index'\n",
    "]\n",
    "\n",
    "# Add lag features\n",
    "lag_cols = [col for col in gas_data.columns if 'lag_' in col or 'ma_' in col or 'std_' in col]\n",
    "feature_cols.extend(lag_cols)\n",
    "\n",
    "# Filter available features\n",
    "available_features = [col for col in feature_cols if col in gas_data.columns]\n",
    "print(f\"\\nüîß Feature Engineering:\")\n",
    "print(f\"   ‚Ä¢ Available features: {len(available_features)}\")\n",
    "print(f\"   ‚Ä¢ Feature categories:\")\n",
    "print(f\"     - Weather: {len([c for c in available_features if 'temp' in c or 'hdd' in c or 'cdd' in c])}\")\n",
    "print(f\"     - Seasonal: {len([c for c in available_features if 'sin' in c or 'cos' in c or 'is_' in c])}\")\n",
    "print(f\"     - Lag/Rolling: {len([c for c in available_features if 'lag_' in c or 'ma_' in c or 'std_' in c])}\")\n",
    "print(f\"     - Economic: {len([c for c in available_features if 'gdp' in c or 'industrial' in c])}\")\n",
    "\n",
    "# Create feature matrix\n",
    "X = gas_data[available_features].dropna()\n",
    "y_aligned = gas_data.loc[X.index, target_col]\n",
    "\n",
    "print(f\"   ‚Ä¢ Final dataset shape: X={X.shape}, y={y_aligned.shape}\")\n",
    "print(f\"   ‚Ä¢ Date range for modeling: {X.index.min().strftime('%Y-%m')} to {X.index.max().strftime('%Y-%m')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51be5116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TRADITIONAL TIME SERIES MODELS ===\n",
    "print(\"üìà TRADITIONAL TIME SERIES FORECASTING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Prepare data for time series models\n",
    "y_ts = gas_data[target_col].dropna()\n",
    "print(f\"Time series data: {len(y_ts)} observations\")\n",
    "\n",
    "# 1. ARIMA Model\n",
    "print(\"\\n1. ARIMA Model:\")\n",
    "try:\n",
    "    # Auto ARIMA with different orders\n",
    "    arima_orders = [(1,0,1), (1,1,1), (2,1,2), (0,1,1)]\n",
    "    arima_results = {}\n",
    "    \n",
    "    for order in arima_orders:\n",
    "        try:\n",
    "            model = ARIMA(y_ts, order=order)\n",
    "            fitted_model = model.fit()\n",
    "            arima_results[order] = {\n",
    "                'model': fitted_model,\n",
    "                'aic': fitted_model.aic,\n",
    "                'bic': fitted_model.bic,\n",
    "                'llf': fitted_model.llf\n",
    "            }\n",
    "            print(f\"   ARIMA{order}: AIC={fitted_model.aic:.2f}, BIC={fitted_model.bic:.2f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ARIMA{order}: Failed - {str(e)[:50]}...\")\n",
    "    \n",
    "    # Select best ARIMA model\n",
    "    if arima_results:\n",
    "        best_order = min(arima_results.keys(), key=lambda x: arima_results[x]['aic'])\n",
    "        best_arima = arima_results[best_order]['model']\n",
    "        print(f\"   ‚úÖ Best ARIMA model: ARIMA{best_order}\")\n",
    "        \n",
    "        # Generate forecast\n",
    "        forecast_steps = 12  # 12 months ahead\n",
    "        arima_forecast = best_arima.forecast(steps=forecast_steps)\n",
    "        arima_conf_int = best_arima.get_forecast(steps=forecast_steps).conf_int()\n",
    "        \n",
    "        print(f\"   üìä ARIMA Forecast (next 12 months):\")\n",
    "        print(f\"      Mean: {arima_forecast.mean():.2f} million m¬≥/month\")\n",
    "        print(f\"      Range: {arima_forecast.min():.2f} - {arima_forecast.max():.2f}\")\n",
    "        \n",
    "        # Calculate in-sample metrics\n",
    "        fitted_values = best_arima.fittedvalues\n",
    "        residuals = y_ts - fitted_values\n",
    "        arima_mae = np.mean(np.abs(residuals))\n",
    "        arima_rmse = np.sqrt(np.mean(residuals**2))\n",
    "        arima_mape = np.mean(np.abs(residuals / y_ts)) * 100\n",
    "        \n",
    "        print(f\"   üìà In-sample Performance:\")\n",
    "        print(f\"      MAE: {arima_mae:.3f}\")\n",
    "        print(f\"      RMSE: {arima_rmse:.3f}\")\n",
    "        print(f\"      MAPE: {arima_mape:.2f}%\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå ARIMA modeling failed: {str(e)}\")\n",
    "    best_arima = None\n",
    "\n",
    "# 2. SARIMA Model (Seasonal ARIMA)\n",
    "print(\"\\n2. SARIMA Model:\")\n",
    "try:\n",
    "    # Try different seasonal orders\n",
    "    sarima_orders = [(1,0,1,12), (1,1,1,12), (2,1,2,12)]\n",
    "    sarima_results = {}\n",
    "    \n",
    "    for order in sarima_orders:\n",
    "        try:\n",
    "            model = SARIMAX(y_ts, order=order[:3], seasonal_order=(1,1,1,12))\n",
    "            fitted_model = model.fit(disp=False)\n",
    "            sarima_results[order] = {\n",
    "                'model': fitted_model,\n",
    "                'aic': fitted_model.aic,\n",
    "                'bic': fitted_model.bic\n",
    "            }\n",
    "            print(f\"   SARIMA{order}: AIC={fitted_model.aic:.2f}, BIC={fitted_model.bic:.2f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   SARIMA{order}: Failed - {str(e)[:50]}...\")\n",
    "    \n",
    "    # Select best SARIMA model\n",
    "    if sarima_results:\n",
    "        best_sarima_order = min(sarima_results.keys(), key=lambda x: sarima_results[x]['aic'])\n",
    "        best_sarima = sarima_results[best_sarima_order]['model']\n",
    "        print(f\"   ‚úÖ Best SARIMA model: SARIMA{best_sarima_order}\")\n",
    "        \n",
    "        # Generate forecast\n",
    "        sarima_forecast = best_sarima.forecast(steps=forecast_steps)\n",
    "        sarima_conf_int = best_sarima.get_forecast(steps=forecast_steps).conf_int()\n",
    "        \n",
    "        print(f\"   üìä SARIMA Forecast (next 12 months):\")\n",
    "        print(f\"      Mean: {sarima_forecast.mean():.2f} million m¬≥/month\")\n",
    "        print(f\"      Range: {sarima_forecast.min():.2f} - {sarima_forecast.max():.2f}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå SARIMA modeling failed: {str(e)}\")\n",
    "    best_sarima = None\n",
    "\n",
    "# 3. Exponential Smoothing\n",
    "print(\"\\n3. Exponential Smoothing (Holt-Winters):\")\n",
    "try:\n",
    "    # Try different seasonal models\n",
    "    exp_models = {}\n",
    "    \n",
    "    # Additive seasonal\n",
    "    try:\n",
    "        model_add = ExponentialSmoothing(y_ts, seasonal='add', seasonal_periods=12)\n",
    "        fitted_add = model_add.fit()\n",
    "        exp_models['additive'] = fitted_add\n",
    "        print(f\"   Additive Seasonal: AIC={fitted_add.aic:.2f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   Additive Seasonal: Failed - {str(e)[:50]}...\")\n",
    "    \n",
    "    # Multiplicative seasonal\n",
    "    try:\n",
    "        model_mult = ExponentialSmoothing(y_ts, seasonal='mul', seasonal_periods=12)\n",
    "        fitted_mult = model_mult.fit()\n",
    "        exp_models['multiplicative'] = fitted_mult\n",
    "        print(f\"   Multiplicative Seasonal: AIC={fitted_mult.aic:.2f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   Multiplicative Seasonal: Failed - {str(e)[:50]}...\")\n",
    "    \n",
    "    # Select best exponential smoothing model\n",
    "    if exp_models:\n",
    "        best_exp_type = min(exp_models.keys(), key=lambda x: exp_models[x].aic)\n",
    "        best_exp = exp_models[best_exp_type]\n",
    "        print(f\"   ‚úÖ Best Exponential Smoothing: {best_exp_type}\")\n",
    "        \n",
    "        # Generate forecast\n",
    "        exp_forecast = best_exp.forecast(steps=forecast_steps)\n",
    "        \n",
    "        print(f\"   üìä Exponential Smoothing Forecast (next 12 months):\")\n",
    "        print(f\"      Mean: {exp_forecast.mean():.2f} million m¬≥/month\")\n",
    "        print(f\"      Range: {exp_forecast.min():.2f} - {exp_forecast.max():.2f}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Exponential Smoothing failed: {str(e)}\")\n",
    "    best_exp = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac60315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MACHINE LEARNING MODELS ===\n",
    "print(\"\\nü§ñ MACHINE LEARNING FORECASTING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Prepare data for ML models\n",
    "print(f\"ML dataset: X={X.shape}, y={y_aligned.shape}\")\n",
    "\n",
    "# Train-test split for ML models\n",
    "split_idx = int(len(X) * 0.8)\n",
    "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_train, y_test = y_aligned.iloc[:split_idx], y_aligned.iloc[split_idx:]\n",
    "\n",
    "print(f\"Train set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "ml_models = {}\n",
    "ml_results = {}\n",
    "\n",
    "# 1. Random Forest\n",
    "print(\"\\n1. Random Forest:\")\n",
    "try:\n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        random_state=42\n",
    "    )\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    rf_pred_train = rf_model.predict(X_train)\n",
    "    rf_pred_test = rf_model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    rf_mae_train = mean_absolute_error(y_train, rf_pred_train)\n",
    "    rf_mae_test = mean_absolute_error(y_test, rf_pred_test)\n",
    "    rf_rmse_train = np.sqrt(mean_squared_error(y_train, rf_pred_train))\n",
    "    rf_rmse_test = np.sqrt(mean_squared_error(y_test, rf_pred_test))\n",
    "    rf_r2_train = r2_score(y_train, rf_pred_train)\n",
    "    rf_r2_test = r2_score(y_test, rf_pred_test)\n",
    "    \n",
    "    ml_models['Random Forest'] = rf_model\n",
    "    ml_results['Random Forest'] = {\n",
    "        'train_mae': rf_mae_train,\n",
    "        'test_mae': rf_mae_test,\n",
    "        'train_rmse': rf_rmse_train,\n",
    "        'test_rmse': rf_rmse_test,\n",
    "        'train_r2': rf_r2_train,\n",
    "        'test_r2': rf_r2_test\n",
    "    }\n",
    "    \n",
    "    print(f\"   ‚úÖ Random Forest trained successfully\")\n",
    "    print(f\"   üìä Performance:\")\n",
    "    print(f\"      Train - MAE: {rf_mae_train:.3f}, RMSE: {rf_rmse_train:.3f}, R¬≤: {rf_r2_train:.3f}\")\n",
    "    print(f\"      Test  - MAE: {rf_mae_test:.3f}, RMSE: {rf_rmse_test:.3f}, R¬≤: {rf_r2_test:.3f}\")\n",
    "    \n",
    "    # Feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': rf_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"   üîç Top 5 Features:\")\n",
    "    for i, (_, row) in enumerate(feature_importance.head().iterrows(), 1):\n",
    "        print(f\"      {i}. {row['feature']:<25}: {row['importance']:.4f}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Random Forest failed: {str(e)}\")\n",
    "\n",
    "# 2. XGBoost\n",
    "print(\"\\n2. XGBoost:\")\n",
    "try:\n",
    "    xgb_model = xgb.XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42\n",
    "    )\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    xgb_pred_train = xgb_model.predict(X_train)\n",
    "    xgb_pred_test = xgb_model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    xgb_mae_train = mean_absolute_error(y_train, xgb_pred_train)\n",
    "    xgb_mae_test = mean_absolute_error(y_test, xgb_pred_test)\n",
    "    xgb_rmse_train = np.sqrt(mean_squared_error(y_train, xgb_pred_train))\n",
    "    xgb_rmse_test = np.sqrt(mean_squared_error(y_test, xgb_pred_test))\n",
    "    xgb_r2_train = r2_score(y_train, xgb_pred_train)\n",
    "    xgb_r2_test = r2_score(y_test, xgb_pred_test)\n",
    "    \n",
    "    ml_models['XGBoost'] = xgb_model\n",
    "    ml_results['XGBoost'] = {\n",
    "        'train_mae': xgb_mae_train,\n",
    "        'test_mae': xgb_mae_test,\n",
    "        'train_rmse': xgb_rmse_train,\n",
    "        'test_rmse': xgb_rmse_test,\n",
    "        'train_r2': xgb_r2_train,\n",
    "        'test_r2': xgb_r2_test\n",
    "    }\n",
    "    \n",
    "    print(f\"   ‚úÖ XGBoost trained successfully\")\n",
    "    print(f\"   üìä Performance:\")\n",
    "    print(f\"      Train - MAE: {xgb_mae_train:.3f}, RMSE: {xgb_rmse_train:.3f}, R¬≤: {xgb_r2_train:.3f}\")\n",
    "    print(f\"      Test  - MAE: {xgb_mae_test:.3f}, RMSE: {xgb_rmse_test:.3f}, R¬≤: {xgb_r2_test:.3f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå XGBoost failed: {str(e)}\")\n",
    "\n",
    "# 3. Support Vector Regression\n",
    "print(\"\\n3. Support Vector Regression:\")\n",
    "try:\n",
    "    svr_model = SVR(\n",
    "        kernel='rbf',\n",
    "        C=1.0,\n",
    "        gamma='scale',\n",
    "        epsilon=0.1\n",
    "    )\n",
    "    svr_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    svr_pred_train = svr_model.predict(X_train_scaled)\n",
    "    svr_pred_test = svr_model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    svr_mae_train = mean_absolute_error(y_train, svr_pred_train)\n",
    "    svr_mae_test = mean_absolute_error(y_test, svr_pred_test)\n",
    "    svr_rmse_train = np.sqrt(mean_squared_error(y_train, svr_pred_train))\n",
    "    svr_rmse_test = np.sqrt(mean_squared_error(y_test, svr_pred_test))\n",
    "    svr_r2_train = r2_score(y_train, svr_pred_train)\n",
    "    svr_r2_test = r2_score(y_test, svr_pred_test)\n",
    "    \n",
    "    ml_models['SVR'] = svr_model\n",
    "    ml_results['SVR'] = {\n",
    "        'train_mae': svr_mae_train,\n",
    "        'test_mae': svr_mae_test,\n",
    "        'train_rmse': svr_rmse_train,\n",
    "        'test_rmse': svr_rmse_test,\n",
    "        'train_r2': svr_r2_train,\n",
    "        'test_r2': svr_r2_test\n",
    "    }\n",
    "    \n",
    "    print(f\"   ‚úÖ SVR trained successfully\")\n",
    "    print(f\"   üìä Performance:\")\n",
    "    print(f\"      Train - MAE: {svr_mae_train:.3f}, RMSE: {svr_rmse_train:.3f}, R¬≤: {svr_r2_train:.3f}\")\n",
    "    print(f\"      Test  - MAE: {svr_mae_test:.3f}, RMSE: {svr_rmse_test:.3f}, R¬≤: {svr_r2_test:.3f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå SVR failed: {str(e)}\")\n",
    "\n",
    "# Model comparison\n",
    "print(f\"\\nüìä MACHINE LEARNING MODEL COMPARISON:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Model':<15} {'Train MAE':<10} {'Test MAE':<10} {'Train R¬≤':<10} {'Test R¬≤':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for model_name, results in ml_results.items():\n",
    "    print(f\"{model_name:<15} {results['train_mae']:<10.3f} {results['test_mae']:<10.3f} \"\n",
    "          f\"{results['train_r2']:<10.3f} {results['test_r2']:<10.3f}\")\n",
    "\n",
    "# Find best model\n",
    "if ml_results:\n",
    "    best_ml_model = min(ml_results.keys(), key=lambda x: ml_results[x]['test_mae'])\n",
    "    print(f\"\\nüèÜ Best ML Model: {best_ml_model} (lowest test MAE)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e253f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PROPHET MODEL ===\n",
    "print(\"\\nüîÆ PROPHET FORECASTING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    # Prepare data for Prophet\n",
    "    prophet_data = pd.DataFrame({\n",
    "        'ds': gas_data.index,\n",
    "        'y': gas_data[target_col]\n",
    "    }).dropna()\n",
    "    \n",
    "    print(f\"Prophet dataset: {len(prophet_data)} observations\")\n",
    "    \n",
    "    # Initialize and fit Prophet model\n",
    "    prophet_model = Prophet(\n",
    "        yearly_seasonality=True,\n",
    "        weekly_seasonality=False,  # Monthly data\n",
    "        daily_seasonality=False,\n",
    "        seasonality_mode='additive',\n",
    "        changepoint_prior_scale=0.05,\n",
    "        seasonality_prior_scale=10.0\n",
    "    )\n",
    "    \n",
    "    # Add custom seasonalities if needed\n",
    "    prophet_model.add_seasonality(name='monthly', period=30.5, fourier_order=5)\n",
    "    \n",
    "    prophet_model.fit(prophet_data)\n",
    "    \n",
    "    # Create future dataframe for forecasting\n",
    "    future_periods = 12  # 12 months ahead\n",
    "    future = prophet_model.make_future_dataframe(periods=future_periods, freq='MS')\n",
    "    \n",
    "    # Generate forecast\n",
    "    forecast = prophet_model.predict(future)\n",
    "    \n",
    "    # Extract forecast values\n",
    "    prophet_forecast = forecast['yhat'].tail(future_periods)\n",
    "    prophet_lower = forecast['yhat_lower'].tail(future_periods)\n",
    "    prophet_upper = forecast['yhat_upper'].tail(future_periods)\n",
    "    \n",
    "    # Calculate in-sample metrics\n",
    "    prophet_fitted = forecast['yhat'].iloc[:-future_periods]\n",
    "    prophet_residuals = prophet_data['y'] - prophet_fitted\n",
    "    prophet_mae = np.mean(np.abs(prophet_residuals))\n",
    "    prophet_rmse = np.sqrt(np.mean(prophet_residuals**2))\n",
    "    prophet_mape = np.mean(np.abs(prophet_residuals / prophet_data['y'])) * 100\n",
    "    \n",
    "    print(f\"   ‚úÖ Prophet model trained successfully\")\n",
    "    print(f\"   üìä In-sample Performance:\")\n",
    "    print(f\"      MAE: {prophet_mae:.3f}\")\n",
    "    print(f\"      RMSE: {prophet_rmse:.3f}\")\n",
    "    print(f\"      MAPE: {prophet_mape:.2f}%\")\n",
    "    print(f\"   üìà Forecast (next 12 months):\")\n",
    "    print(f\"      Mean: {prophet_forecast.mean():.2f} million m¬≥/month\")\n",
    "    print(f\"      Range: {prophet_forecast.min():.2f} - {prophet_forecast.max():.2f}\")\n",
    "    print(f\"      Confidence interval: {prophet_lower.mean():.2f} - {prophet_upper.mean():.2f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Prophet modeling failed: {str(e)}\")\n",
    "    prophet_model = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d90746d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ENSEMBLE FORECASTING ===\n",
    "print(\"\\nüéØ ENSEMBLE FORECASTING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Collect all forecasts\n",
    "all_forecasts = {}\n",
    "forecast_dates = pd.date_range(start=gas_data.index.max() + pd.DateOffset(months=1), periods=12, freq='MS')\n",
    "\n",
    "# Add time series forecasts\n",
    "if 'best_arima' in locals() and best_arima is not None:\n",
    "    all_forecasts['ARIMA'] = arima_forecast\n",
    "if 'best_sarima' in locals() and best_sarima is not None:\n",
    "    all_forecasts['SARIMA'] = sarima_forecast\n",
    "if 'best_exp' in locals() and best_exp is not None:\n",
    "    all_forecasts['Exponential Smoothing'] = exp_forecast\n",
    "if 'prophet_model' in locals() and prophet_model is not None:\n",
    "    all_forecasts['Prophet'] = prophet_forecast.values\n",
    "\n",
    "# Generate ML forecasts for future periods\n",
    "print(\"Generating ML forecasts for future periods...\")\n",
    "\n",
    "# Create future feature matrix for ML models\n",
    "last_date = X.index.max()\n",
    "future_features = []\n",
    "\n",
    "for i, future_date in enumerate(forecast_dates):\n",
    "    feature_row = {}\n",
    "    \n",
    "    # Use seasonal patterns for future features\n",
    "    for col in X.columns:\n",
    "        if 'month_sin' in col or 'month_cos' in col:\n",
    "            month = future_date.month\n",
    "            if 'sin' in col:\n",
    "                feature_row[col] = np.sin(2 * np.pi * month / 12)\n",
    "            else:\n",
    "                feature_row[col] = np.cos(2 * np.pi * month / 12)\n",
    "        elif 'day_of_year_sin' in col or 'day_of_year_cos' in col:\n",
    "            day_of_year = future_date.timetuple().tm_yday\n",
    "            if 'sin' in col:\n",
    "                feature_row[col] = np.sin(2 * np.pi * day_of_year / 365.25)\n",
    "            else:\n",
    "                feature_row[col] = np.cos(2 * np.pi * day_of_year / 365.25)\n",
    "        elif 'is_winter' in col:\n",
    "            feature_row[col] = 1 if future_date.month in [12, 1, 2] else 0\n",
    "        elif 'is_spring' in col:\n",
    "            feature_row[col] = 1 if future_date.month in [3, 4, 5] else 0\n",
    "        elif 'is_summer' in col:\n",
    "            feature_row[col] = 1 if future_date.month in [6, 7, 8] else 0\n",
    "        elif 'is_autumn' in col:\n",
    "            feature_row[col] = 1 if future_date.month in [9, 10, 11] else 0\n",
    "        elif 'avg_temperature_celsius' in col:\n",
    "            # Seasonal temperature estimate\n",
    "            seasonal_temp = 15 + 10 * np.sin(2 * np.pi * (future_date.month - 7) / 12)\n",
    "            feature_row[col] = seasonal_temp\n",
    "        elif 'heating_degree_days' in col:\n",
    "            temp = 15 + 10 * np.sin(2 * np.pi * (future_date.month - 7) / 12)\n",
    "            feature_row[col] = max(0, 18 - temp) * 30\n",
    "        elif 'cooling_degree_days' in col:\n",
    "            temp = 15 + 10 * np.sin(2 * np.pi * (future_date.month - 7) / 12)\n",
    "            feature_row[col] = max(0, temp - 24) * 30\n",
    "        elif 'lag_' in col or 'ma_' in col or 'std_' in col:\n",
    "            # Use historical averages for lag features\n",
    "            feature_row[col] = X[col].mean()\n",
    "        else:\n",
    "            # Use historical mean for other features\n",
    "            feature_row[col] = X[col].mean()\n",
    "    \n",
    "    future_features.append(feature_row)\n",
    "\n",
    "future_X = pd.DataFrame(future_features)\n",
    "\n",
    "# Generate ML forecasts\n",
    "for model_name, model in ml_models.items():\n",
    "    try:\n",
    "        if model_name == 'SVR':\n",
    "            future_X_scaled = scaler.transform(future_X)\n",
    "            ml_forecast = model.predict(future_X_scaled)\n",
    "        else:\n",
    "            ml_forecast = model.predict(future_X)\n",
    "        \n",
    "        all_forecasts[model_name] = ml_forecast\n",
    "        print(f\"   ‚úÖ {model_name} forecast generated\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå {model_name} forecast failed: {str(e)}\")\n",
    "\n",
    "# Create ensemble forecast\n",
    "if len(all_forecasts) > 1:\n",
    "    print(f\"\\nüéØ Creating ensemble forecast from {len(all_forecasts)} models...\")\n",
    "    \n",
    "    # Simple average ensemble\n",
    "    ensemble_values = np.mean(list(all_forecasts.values()), axis=0)\n",
    "    \n",
    "    # Weighted ensemble (based on inverse MAE)\n",
    "    weights = {}\n",
    "    for model_name in all_forecasts.keys():\n",
    "        if model_name in ml_results:\n",
    "            weights[model_name] = 1 / ml_results[model_name]['test_mae']\n",
    "        else:\n",
    "            weights[model_name] = 1.0  # Equal weight for time series models\n",
    "    \n",
    "    # Normalize weights\n",
    "    total_weight = sum(weights.values())\n",
    "    weights = {k: v/total_weight for k, v in weights.items()}\n",
    "    \n",
    "    weighted_ensemble = np.zeros(len(forecast_dates))\n",
    "    for model_name, forecast in all_forecasts.items():\n",
    "        weighted_ensemble += weights[model_name] * forecast\n",
    "    \n",
    "    print(f\"   üìä Ensemble Forecast Results:\")\n",
    "    print(f\"      Simple Average: {ensemble_values.mean():.2f} ¬± {ensemble_values.std():.2f} million m¬≥/month\")\n",
    "    print(f\"      Weighted Average: {weighted_ensemble.mean():.2f} ¬± {weighted_ensemble.std():.2f} million m¬≥/month\")\n",
    "    \n",
    "    # Store ensemble forecasts\n",
    "    all_forecasts['Ensemble (Simple)'] = ensemble_values\n",
    "    all_forecasts['Ensemble (Weighted)'] = weighted_ensemble\n",
    "    \n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è Insufficient models for ensemble forecasting\")\n",
    "\n",
    "print(f\"\\nüìà FORECAST SUMMARY:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Model':<20} {'Mean Forecast':<15} {'Std Dev':<10} {'Range':<20}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for model_name, forecast in all_forecasts.items():\n",
    "    print(f\"{model_name:<20} {forecast.mean():<15.2f} {forecast.std():<10.2f} \"\n",
    "          f\"{forecast.min():.1f}-{forecast.max():.1f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ All forecasting models completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d6b0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === FORECAST VISUALIZATION ===\n",
    "print(\"\\nüìä CREATING FORECAST VISUALIZATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create comprehensive forecast visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Japan Gas Demand Forecasting - Model Comparison', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Historical data with forecasts\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(gas_data.index, gas_data[target_col], 'b-', linewidth=2, label='Historical Data', alpha=0.8)\n",
    "\n",
    "# Plot individual forecasts\n",
    "colors = ['red', 'green', 'orange', 'purple', 'brown', 'pink', 'gray']\n",
    "for i, (model_name, forecast) in enumerate(all_forecasts.items()):\n",
    "    if len(forecast) == len(forecast_dates):\n",
    "        ax1.plot(forecast_dates, forecast, '--', color=colors[i % len(colors)], \n",
    "                linewidth=2, alpha=0.7, label=f'{model_name}')\n",
    "\n",
    "ax1.set_title('Historical Data vs Model Forecasts', fontweight='bold')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Gas Demand (Million m¬≥/month)')\n",
    "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Forecast comparison (bar chart)\n",
    "ax2 = axes[0, 1]\n",
    "model_names = list(all_forecasts.keys())\n",
    "forecast_means = [forecast.mean() for forecast in all_forecasts.values()]\n",
    "forecast_stds = [forecast.std() for forecast in all_forecasts.values()]\n",
    "\n",
    "bars = ax2.bar(range(len(model_names)), forecast_means, yerr=forecast_stds, \n",
    "               capsize=5, alpha=0.7, color=colors[:len(model_names)])\n",
    "ax2.set_title('Forecast Comparison (12-Month Average)', fontweight='bold')\n",
    "ax2.set_xlabel('Model')\n",
    "ax2.set_ylabel('Average Forecast (Million m¬≥/month)')\n",
    "ax2.set_xticks(range(len(model_names)))\n",
    "ax2.set_xticklabels(model_names, rotation=45, ha='right')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, mean_val in zip(bars, forecast_means):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 10,\n",
    "             f'{mean_val:.1f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 3. Model performance comparison (if available)\n",
    "ax3 = axes[1, 0]\n",
    "if ml_results:\n",
    "    ml_names = list(ml_results.keys())\n",
    "    test_maes = [ml_results[name]['test_mae'] for name in ml_names]\n",
    "    \n",
    "    bars = ax3.bar(ml_names, test_maes, alpha=0.7, color=['red', 'green', 'blue'][:len(ml_names)])\n",
    "    ax3.set_title('Model Performance (Test MAE)', fontweight='bold')\n",
    "    ax3.set_ylabel('Test MAE (Million m¬≥/month)')\n",
    "    ax3.set_xlabel('Model')\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, mae in zip(bars, test_maes):\n",
    "        ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                 f'{mae:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    ax3.grid(True, alpha=0.3, axis='y')\n",
    "else:\n",
    "    ax3.text(0.5, 0.5, 'ML Performance\\nData Not Available', \n",
    "             ha='center', va='center', transform=ax3.transAxes, fontsize=12)\n",
    "    ax3.set_title('Model Performance - No Data', fontweight='bold')\n",
    "\n",
    "# 4. Forecast uncertainty (if ensemble available)\n",
    "ax4 = axes[1, 1]\n",
    "if 'Ensemble (Simple)' in all_forecasts:\n",
    "    ensemble_forecast = all_forecasts['Ensemble (Simple)']\n",
    "    \n",
    "    # Calculate confidence intervals\n",
    "    forecast_mean = ensemble_forecast.mean()\n",
    "    forecast_std = ensemble_forecast.std()\n",
    "    \n",
    "    # Plot forecast with confidence bands\n",
    "    ax4.plot(forecast_dates, ensemble_forecast, 'b-', linewidth=2, label='Ensemble Forecast')\n",
    "    ax4.fill_between(forecast_dates, \n",
    "                     ensemble_forecast - 1.96 * forecast_std,\n",
    "                     ensemble_forecast + 1.96 * forecast_std,\n",
    "                     alpha=0.3, color='blue', label='95% Confidence Interval')\n",
    "    \n",
    "    ax4.set_title('Ensemble Forecast with Uncertainty', fontweight='bold')\n",
    "    ax4.set_xlabel('Date')\n",
    "    ax4.set_ylabel('Gas Demand (Million m¬≥/month)')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "else:\n",
    "    ax4.text(0.5, 0.5, 'Ensemble Forecast\\nNot Available', \n",
    "             ha='center', va='center', transform=ax4.transAxes, fontsize=12)\n",
    "    ax4.set_title('Ensemble Forecast - No Data', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create detailed forecast table\n",
    "print(f\"\\nüìã DETAILED FORECAST TABLE:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create forecast DataFrame\n",
    "forecast_df = pd.DataFrame({\n",
    "    'Date': forecast_dates,\n",
    "    **{model_name: forecast for model_name, forecast in all_forecasts.items()}\n",
    "})\n",
    "\n",
    "print(\"Next 12 months forecast (Million m¬≥/month):\")\n",
    "print(forecast_df.round(2))\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nüìä FORECAST SUMMARY STATISTICS:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"‚Ä¢ Total models trained: {len(all_forecasts)}\")\n",
    "print(f\"‚Ä¢ Forecast horizon: 12 months\")\n",
    "print(f\"‚Ä¢ Forecast period: {forecast_dates[0].strftime('%Y-%m')} to {forecast_dates[-1].strftime('%Y-%m')}\")\n",
    "\n",
    "if 'Ensemble (Simple)' in all_forecasts:\n",
    "    ensemble_mean = all_forecasts['Ensemble (Simple)'].mean()\n",
    "    ensemble_std = all_forecasts['Ensemble (Simple)'].std()\n",
    "    print(f\"‚Ä¢ Recommended forecast (Ensemble): {ensemble_mean:.2f} ¬± {ensemble_std:.2f} million m¬≥/month\")\n",
    "    print(f\"‚Ä¢ Annual forecast: {ensemble_mean * 12:.0f} million m¬≥/year\")\n",
    "\n",
    "print(f\"\\n‚úÖ Forecast visualization and analysis complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cd9ccd",
   "metadata": {},
   "source": [
    "# Japan Gas Demand Forecasting Models\n",
    "\n",
    "This notebook implements and compares multiple forecasting approaches for short-term gas demand in Japan, including traditional time series models and machine learning techniques.\n",
    "\n",
    "## Objectives\n",
    "1. Implement ARIMA/SARIMA models for time series forecasting\n",
    "2. Build exponential smoothing models (Holt-Winters)\n",
    "3. Develop machine learning models (Random Forest, XGBoost)\n",
    "4. Create ensemble forecasting approaches\n",
    "5. Compare model performance using appropriate metrics\n",
    "6. Generate short-term forecasts with uncertainty estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50f6b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for forecasting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Time series modeling\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# Plotting\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Set styling and suppress warnings\n",
    "plt.style.use('seaborn-v0_8')\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"üöÄ Forecasting libraries imported successfully!\")\n",
    "print(f\"Model development started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67924a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the synthetic gas demand data for modeling\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create date range and synthetic data (same as EDA notebook)\n",
    "start_date = pd.Timestamp('2018-01-01')\n",
    "end_date = pd.Timestamp('2024-08-31') \n",
    "dates = pd.date_range(start_date, end_date, freq='MS')\n",
    "\n",
    "def generate_realistic_gas_data():\n",
    "    \"\"\"Generate synthetic but realistic Japanese gas demand data\"\"\"\n",
    "    n_months = len(dates)\n",
    "    base_monthly = 37000 / 12  # Million cubic meters per month\n",
    "    \n",
    "    # Components\n",
    "    trend = np.linspace(1.0, 0.95, n_months)\n",
    "    months = np.array([d.month for d in dates])\n",
    "    seasonal = 1.0 + 0.4 * np.cos(2 * np.pi * (months - 1) / 12)\n",
    "    \n",
    "    # COVID impact\n",
    "    covid_impact = np.ones(n_months)\n",
    "    for i, date in enumerate(dates):\n",
    "        if pd.Timestamp('2020-03-01') <= date <= pd.Timestamp('2021-06-01'):\n",
    "            covid_impact[i] = 0.85\n",
    "    \n",
    "    noise = 1.0 + np.random.normal(0, 0.05, n_months)\n",
    "    gas_demand = base_monthly * trend * seasonal * covid_impact * noise\n",
    "    \n",
    "    # Weather variables\n",
    "    avg_temp = np.array([15 + 10 * np.cos(2 * np.pi * (d.month - 7) / 12) + \n",
    "                        np.random.normal(0, 2) for d in dates])\n",
    "    hdd = np.maximum(0, 18 - avg_temp) * 30\n",
    "    cdd = np.maximum(0, avg_temp - 22) * 30\n",
    "    \n",
    "    # Economic variables\n",
    "    gdp_growth = np.random.normal(0.8, 1.0, n_months)\n",
    "    gas_price = 45 + 10 * np.sin(2 * np.pi * np.arange(n_months) / 12) + np.random.normal(0, 2, n_months)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'date': dates,\n",
    "        'gas_demand': gas_demand,\n",
    "        'temperature': avg_temp,\n",
    "        'heating_degree_days': hdd,\n",
    "        'cooling_degree_days': cdd,\n",
    "        'gdp_growth': gdp_growth,\n",
    "        'gas_price': gas_price\n",
    "    }).set_index('date')\n",
    "\n",
    "# Generate the dataset\n",
    "gas_data = generate_realistic_gas_data()\n",
    "\n",
    "print(\"üìä DATASET FOR FORECASTING MODELS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Period: {gas_data.index.min().strftime('%Y-%m')} to {gas_data.index.max().strftime('%Y-%m')}\")\n",
    "print(f\"Observations: {len(gas_data)} monthly records\")\n",
    "print(f\"Variables: {len(gas_data.columns)}\")\n",
    "print(f\"\\nTarget variable statistics:\")\n",
    "print(f\"Mean gas demand: {gas_data['gas_demand'].mean():.1f} million m¬≥/month\")\n",
    "print(f\"Standard deviation: {gas_data['gas_demand'].std():.1f} million m¬≥/month\")\n",
    "print(f\"Coefficient of variation: {(gas_data['gas_demand'].std()/gas_data['gas_demand'].mean()*100):.1f}%\")\n",
    "\n",
    "# Display first and last few observations\n",
    "print(f\"\\nFirst 5 observations:\")\n",
    "print(gas_data.head())\n",
    "print(f\"\\nLast 5 observations:\")\n",
    "print(gas_data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b05af38",
   "metadata": {},
   "source": [
    "## 1. Model Evaluation Framework\n",
    "\n",
    "Setting up comprehensive evaluation metrics and validation procedures for time series forecasting."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
